{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb0fe8da3d79efd",
   "metadata": {},
   "source": [
    "# Homework 5: 12707 and 12607\n",
    "\n",
    "Homework created by Ryan Albelda \n",
    "Inspired by: https://curiousily.com/posts/build-your-first-neural-network-with-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89adc405c5d95c",
   "metadata": {},
   "source": [
    "## Build Your First Neural Network with PyTorch\n",
    "\n",
    "This homework is out of 50 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5225b8b32648642",
   "metadata": {},
   "source": [
    "### About data: \n",
    "This archive contains 2075259 measurements gathered in a house located in Sceaux (7km of Paris, France) between December 2006 and November 2010 (47 months). Measurements of electric power consumption in one household with a one-minute sampling rate over a period of almost 4 years. Different electrical quantities and some sub-metering values are available.\n",
    "\n",
    "Learn more about the data here: https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption\n",
    "\n",
    "Citation: \n",
    "Hebrail, G. & Berard, A. (2006). Individual Household Electric Power Consumption [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C58K54."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c939c5f6020826",
   "metadata": {},
   "source": [
    "# Part 1: Name, Homework Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761c95ea781f78e5",
   "metadata": {},
   "source": [
    "#### 1) Name, Andrew ID, Time to finish the homework \n",
    "*12607: 3 points, 12707: 3 points*\n",
    "\n",
    "'###' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af325d2cfbfe0d8f",
   "metadata": {},
   "source": [
    "##### Objectives of Homework\n",
    "- Clean data to be numeric and remove missing rows \n",
    "- Separate features and target variable \n",
    "- Use standard scalar and why we are using tensors. Learn what tensors are here\n",
    "- Use torch.nn.Module and understand how to read it: understand how layers of nodes correspond to lines of code\n",
    "- Find the activation function part of the NN \n",
    "- Understand the tools for error metrics in a NN \n",
    "- Understand there is optimizer tool for NN and research other optimizer methods\n",
    "- Learn what a learning rate is \n",
    "- Understand how epoch ties into loss errors \n",
    "- Convert data to be binary classification and apply various model metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184d68d75672715a",
   "metadata": {},
   "source": [
    "# Part 2: Loading Data and cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20065769be683287",
   "metadata": {},
   "source": [
    "#### Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:44:54.058893Z",
     "start_time": "2025-04-07T13:44:54.056983Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch import nn, optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.image as mpimg"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "3a7d60b9c9555112",
   "metadata": {},
   "source": [
    "#### Import Data and look at the data "
   ]
  },
  {
   "cell_type": "code",
   "id": "733aec5e1e4ff564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:44:54.888525Z",
     "start_time": "2025-04-07T13:44:54.120022Z"
    }
   },
   "source": [
    "df = pd.read_csv('household_power_consumption.csv', sep=',', low_memory=False)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "204ffd37d626c73a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:44:54.893480Z",
     "start_time": "2025-04-07T13:44:54.889553Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Unnamed: 0        Date      Time Global_active_power Global_reactive_power  \\\n",
       "0           0  16/12/2006  17:24:00               4.216                 0.418   \n",
       "1           1  16/12/2006  17:25:00               5.360                 0.436   \n",
       "2           2  16/12/2006  17:26:00               5.374                 0.498   \n",
       "3           3  16/12/2006  17:27:00               5.388                 0.502   \n",
       "4           4  16/12/2006  17:28:00               3.666                 0.528   \n",
       "\n",
       "   Voltage Global_intensity Sub_metering_1 Sub_metering_2  Sub_metering_3  \n",
       "0  234.840           18.400          0.000          1.000            17.0  \n",
       "1  233.630           23.000          0.000          1.000            16.0  \n",
       "2  233.290           23.000          0.000          2.000            17.0  \n",
       "3  233.740           23.000          0.000          1.000            17.0  \n",
       "4  235.680           15.800          0.000          1.000            17.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:24:00</td>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.840</td>\n",
       "      <td>18.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:25:00</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:26:00</td>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.290</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:27:00</td>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:28:00</td>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.680</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "1360b05a67752349",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:44:54.897628Z",
     "start_time": "2025-04-07T13:44:54.894106Z"
    }
   },
   "source": [
    "df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075259 entries, 0 to 2075258\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   Unnamed: 0             int64  \n",
      " 1   Date                   object \n",
      " 2   Time                   object \n",
      " 3   Global_active_power    object \n",
      " 4   Global_reactive_power  object \n",
      " 5   Voltage                object \n",
      " 6   Global_intensity       object \n",
      " 7   Sub_metering_1         object \n",
      " 8   Sub_metering_2         object \n",
      " 9   Sub_metering_3         float64\n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 158.3+ MB\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "42cb4c5faa7c45d2",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315de1efc35970d3",
   "metadata": {},
   "source": [
    "#### 2) Clean the data \n",
    "* Convert all columns (except Date, Time, and Unnamed: 0) to numeric\n",
    "* Fix the dropping line `df.###` to drop the rows with missing values. \n",
    "    * Per data documentation there are missing values:https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption\n",
    "        * If this was 100 point assignment you would explore if the values are missing  \n",
    "* Drop  'Date', 'Time', and  'Unnamed: 0'  columns\n",
    "\n",
    "*12607: 8 points, 12707: 6 points*\n",
    "\n",
    "'###'"
   ]
  },
  {
   "cell_type": "code",
   "id": "145eed03f3d3f54f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:44:54.900522Z",
     "start_time": "2025-04-07T13:44:54.898556Z"
    }
   },
   "source": [
    "# Convert all columns (except Date, Time, and Unnamed: 0) to numeric\n",
    "for col in df.columns:\n",
    "    if col not in [###]:\n",
    "        df[col] = pd.to_numeric(df[###], errors='coerce')\n",
    "        \n",
    "# Drop rows with missing values\n",
    "df.###(inplace=True)\n",
    "\n",
    "# Drop 'Date', 'Time',and  'Unnamed: 0'  columns\n",
    "df.drop(columns=[###], inplace=True)\n"
   ],
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'[' was never closed (124557764.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[16], line 10\u001B[0;36m\u001B[0m\n\u001B[0;31m    df.drop(columns=[###], inplace=True)\u001B[0m\n\u001B[0m                    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m '[' was never closed\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "e7082ed5c0dc1fa9",
   "metadata": {},
   "source": [
    "### More Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "id": "f7a92b1864668dfe",
   "metadata": {},
   "source": [
    "# No categorical features left, so this will not change the dataframe, but safe to keep:\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a9359b91f51ce5ba",
   "metadata": {},
   "source": [
    "#### Test and Train data Set\n",
    "\n",
    "#### 3) Separate the Features and Targets: \n",
    "- Our target variable is `Global_active_power`\n",
    "\n",
    "*12607: 5 points, 12707: 4 points*\n",
    "\n",
    "'###'"
   ]
  },
  {
   "cell_type": "code",
   "id": "17ae38bfb614b4a8",
   "metadata": {},
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns='###')\n",
    "y = ###\n",
    "# Train-test split\n",
    "# DO NOT CHANGE THIS, we want everyone to get the same results for this homework \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=14)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "70ce7772e1867e3c",
   "metadata": {},
   "source": [
    "The code scales training and test features using StandardScaler, then converts both the features (X_train, X_test) and labels (y_train, y_test) into PyTorch tensors for use in a neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0794c4c2120e9d6",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "code",
   "id": "ee25415c65fcb270",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).float())\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9d15502f43aee55d",
   "metadata": {},
   "source": [
    "We use StandardScaler to normalize the features so that each one has a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "This helps neural networks (and many other ML models) train faster and more reliably by:\n",
    "\n",
    "   1)  Preventing features with large scales from dominating others\n",
    "\n",
    "   2) Helping gradients flow better, especially in deep networks\n",
    "\n",
    "   3) Improving model convergence during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4af7aeb45f313b",
   "metadata": {},
   "source": [
    "# Part 3: Building a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41839ce8754269e1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We’ll build a simple Neural Network (NN) that predicts the global active power consumption of a building.\n",
    "\n",
    "Our input will use data from several sensor-based features (e.g., voltage, current, sub-metering values). We’ll create an appropriate input layer that matches the number of these features.\n",
    "\n",
    "The output will be a single number representing the predicted Global_active_power usage at a given time.\n",
    "\n",
    "We’ll include two hidden layers between the input and output layers. These hidden layers learn internal representations that help the model make accurate predictions. All layers will be fully connected (dense).\n",
    "\n",
    "To implement this, we’ll define a PyTorch neural network class that inherits from torch.nn.Module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6479111cd46f033",
   "metadata": {},
   "source": [
    "#### 4) Research and write 1-3 sentences exploring what the torch.nn.Module is and its function.  12707: Why does it have different layer types? \n",
    "\n",
    "*12607: 4 points (only explore and write function), 12707: 4 points, answer layer question too*\n",
    "\n",
    "\n",
    "'###'\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e3164e6c441b48fe",
   "metadata": {},
   "source": [
    "# Define neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, 5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x))\n",
    "\n",
    "net = Net(X_train.shape[1])\n",
    "print(net)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7616bd89e9e09769",
   "metadata": {},
   "source": [
    "# Run code to see image\n",
    "img = mpimg.imread(\"NN_HW5.png\")\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cd055e034c2e8686",
   "metadata": {},
   "source": [
    "#### 5) We are going to focus on: \n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, 5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "        \n",
    "Part of the code. \n",
    "\n",
    "Using the image for help, explain in 1-2 sentences how `self.fc2 = nn.Linear(5, 3)` is different from `self.fc3 = nn.Linear(3, 1)`. \n",
    "\n",
    "12707 only: Also, looking at the image:  One of these layers, in the image, is not a correct representation of the network in the code. What layer is it? In what way is it incorrect? \n",
    "\n",
    "*12607: 6 points (skip how image is incorrect), 12707: 6 points*\n",
    "\n",
    "\n",
    "\n",
    "'###'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89afeb967fc22bc1",
   "metadata": {},
   "source": [
    "\n",
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281b4383704adfad",
   "metadata": {},
   "source": [
    "We start by creating the layers of our model in the constructor. The forward() method is where the magic happens. It accepts the input x and allows it to flow through each layer. There is a corresponding backward pass (defined for you by PyTorch) that allows the model to learn from the errors that is currently making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64cc9d081be1fc6",
   "metadata": {},
   "source": [
    "# Part 4: Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d003d23d701889",
   "metadata": {},
   "source": [
    "You might notice the calls to F.relu and torch.sigmoid. Why do we need those?\n",
    "\n",
    "One of the cool features of Neural Networks is that they can approximate non-linear functions. In fact, it is proven that they can approximate any function.\n",
    "\n",
    "It is difficult to approximate non-linear functions using only linear layers. Activation functions allow you to break from the linear world and learn (hopefully) more. You’ll usually find them applied to an output of some layer.\n",
    "\n",
    "Those functions must be hard to define, right?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a13b554ac5ca137",
   "metadata": {},
   "source": [
    "### ReLU\n",
    "\n",
    "Not at all, let start with the ReLU definition (one of the most widely used activation function):\n",
    "\n",
    "`ReLU(x)=max(0,x)`\n",
    "\n",
    "\n",
    "Easy peasy, the result is the maximum value of zero and the input:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run code to see image\n",
    "img = mpimg.imread(\"ReLu.png\")\n",
    "# Display the image\n",
    "plt.imshow(img) \n",
    "plt.axis('off')   \n",
    "plt.show()"
   ],
   "id": "600b2cd5d4c289b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "415fbe4c87a4fc16",
   "metadata": {},
   "source": [
    "### Sigmoid\n",
    "\n",
    "The sigmoid is useful when you need to make a binary decision/classification (answering with a yes or a no).\n",
    "\n",
    "`Sigmoid(x)= 1 / (1 + e^-x)`\n",
    "\n",
    "\n",
    "The sigmoid squishes the input values between 0 and 1. But in a super kind of way:\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run code to see image\n",
    "img = mpimg.imread(\"Sigmoid.png\")\n",
    "# Display the image\n",
    "plt.imshow(img) \n",
    "plt.axis('off')   \n",
    "plt.show()"
   ],
   "id": "bb19cf2de73d600",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "65d427deb77b2929",
   "metadata": {},
   "source": [
    "\n",
    "Back to the code. \n",
    "\n",
    "#### 6) Use of activation functions: \n",
    "\n",
    "       def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x))\n",
    " \n",
    "In a simple explanation, (1-3 sentences), what is the purpose of these activation functions. Note how `F.relu(self.fc2(x))` is different from `torch.sigmoid(self.fc3(x))`  (no math required in answer)  \n",
    "\n",
    "12707: How might things change in the function of the network if we added another layer?   \n",
    "\n",
    "\n",
    "*12607: 5 points (skip how network would change), 12707: 4 points*\n",
    "\n",
    "\n",
    "\n",
    "'###'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8923e6e6abca074",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501fd9c843d43b8",
   "metadata": {},
   "source": [
    "# Part 5: Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13626d49aa9537fd",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ee7fd5a8fc9fe",
   "metadata": {},
   "source": [
    "With the model in place, we need to find parameters that predict the future power. First, we need something to tell us how good we’re currently doing:"
   ]
  },
  {
   "cell_type": "code",
   "id": "ebecc1ca2c381d1f",
   "metadata": {},
   "source": [
    "criterion = nn.MSELoss()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2fc4f49b2215132e",
   "metadata": {},
   "source": [
    "\n",
    "The Mean Squared Error (MSE) loss is a function that measures the average squared difference between the predicted values of a model and the actual values. In our case, it compares the model's predictions with the true values. It does not require the predictions to be passed through a sigmoid function; instead, it works directly with the raw output of the model. The closer this value gets to 0, the more accurate your model's predictions are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c832cdd762b254f",
   "metadata": {},
   "source": [
    "#### 7) Look up another loss function, in PyTorch, that can be used in an NN. 12707: Explain how this is different then MSEloss. Write 1-3 sentences about this method.\n",
    "\n",
    "*12607: 2 points (skip how it is different), 12707: 4 points*\n",
    "\n",
    "'###'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d69676cbb11c32b",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13a97fcecd8739f",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255087a6e4a85ce",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Imagine that each parameter of our NN is a knob. The optimizer’s job is to find the perfect positions for each knob so that the loss gets close to 0.\n",
    "\n",
    "Real-world models can contain millions or even billions of parameters. With so many knobs to turn, it would be nice to have an efficient optimizer that quickly finds solutions.\n",
    "\n",
    "Contrary to what you might believe, optimization in Deep Learning is just satisfying. In practice, you’re content with good enough parameter values that give you an acceptable accuracy.\n",
    "\n",
    "While there are tons of optimizers you can choose from, Adam is a safe first choice. PyTorch has a well-debugged implementation you can use:"
   ]
  },
  {
   "cell_type": "code",
   "id": "7648d73f3894ce19",
   "metadata": {},
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af4b5d26d4d50780",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Naturally, the optimizer requires the parameters. The second argument lr is learning rate. It is a tradeoff between how good parameters you’re going to find and how fast you’ll get there. Finding good values for this can be black magic and a lot of brute-force “experimentation”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119bcb04bda5802",
   "metadata": {},
   "source": [
    "#### 8) Research another optimizer algorithm, in PyTorch, that one can use for NN. 12707: How is this one different then optim.Adam?  Write 1-3 sentences about this algorithm. \n",
    "\n",
    "*12607: 2 points (skip how it is different), 12707: 4 points*\n",
    "\n",
    "Provide citation if applies to your answer. \n",
    "\n",
    "'###'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed3e9818199d89",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2030222c6334b",
   "metadata": {},
   "source": [
    "#### 9) What does lr = 0.001 mean? What would it mean if it was 0.1? What would it mean if it was 0.0000001?\n",
    "\n",
    "*12607: 3 points,  12707: 3 points*\n",
    "\n",
    "\n",
    "'###'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b5e6123b14ec41",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade629e8e7149ee0",
   "metadata": {},
   "source": [
    "# Part 6: Energy Consumption Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a58c363a5c910",
   "metadata": {},
   "source": [
    "With all the pieces of the puzzle in place, we can start training our model:\n",
    "\n",
    "*Note this will take a few minutes to run*"
   ]
  },
  {
   "cell_type": "code",
   "id": "6240175e03e6e3bf",
   "metadata": {},
   "source": [
    "def round_tensor(t, decimal_places=3):\n",
    "    return round(t.item(), decimal_places) \n",
    "# Training loop (modified for regression)\n",
    "for epoch in range(1500):\n",
    "    net.train()\n",
    "    y_pred = net(X_train).squeeze()\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            y_test_pred = net(X_test).squeeze()\n",
    "            test_loss = criterion(y_test_pred, y_test)\n",
    "            print(\n",
    "f'''epoch {epoch}\n",
    "Train set - loss: {round_tensor(train_loss)}\n",
    "Test  set - loss: {round_tensor(test_loss)}\n",
    "''')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e4356ba9dfece113",
   "metadata": {},
   "source": [
    "#### 10) How long did this take your computer to run? Note: the time should be listed at the bottom of the cell. If no time provided by your machine, an estimate is fine. \n",
    "#### Why do you think it took so long? What does epoch 1500 means here? Do you notice anything happening to the loss value? Does the loss value always get significantly better (over 5% change)  with every epoch? \n",
    "\n",
    "\n",
    "*if taking over 8 mins to run set the for epoch in range(1500) to be range (1000)*\n",
    "\n",
    "*12607: 5 points , 12707: 5 points*\n",
    "\n",
    "'###'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a422979a7494ad",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c61311fe8ee788",
   "metadata": {},
   "source": "During training, we present the data to the model repeatedly over multiple epochs. For each epoch, we measure the loss, backpropagate the error, and update the model parameters using the optimizer.\n"
  },
  {
   "cell_type": "markdown",
   "id": "5161d60667d9116a",
   "metadata": {},
   "source": [
    "# Part 7: Evaluation, using binary classification methods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178c23e95b8675f",
   "metadata": {},
   "source": [
    "To help us do the classification we are going to set a threshold level for global active power. We want to see the likelihood of it being more than 0.4. "
   ]
  },
  {
   "cell_type": "code",
   "id": "a163089094f42768",
   "metadata": {},
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose threshold to define \"high power usage\"\n",
    "threshold = 0.4\n",
    "\n",
    "\n",
    "# Binarize true labels\n",
    "y_test_class = (y_test > threshold).int()\n",
    "\n",
    "# Get predictions from model\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = net(X_test).squeeze()\n",
    "\n",
    "# Binarize predictions\n",
    "y_pred_class = (y_test_pred > threshold).int()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e6b6c524329418a",
   "metadata": {},
   "source": [
    "plt.hist(y_test_pred.numpy(), bins=40)\n",
    "plt.axvline(threshold, color='red', linestyle='--', label=f'Threshold = {threshold}')\n",
    "plt.title('Predicted Values Distribution')\n",
    "plt.xlabel('Predicted Global Active Power')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "423ee41f7e93b1dc",
   "metadata": {},
   "source": [
    "### 11) Print out the accuracy, precision, recall, and f1 score\n",
    "\n",
    "*12607: 6 points , 12707: 6 points*\n",
    "\n",
    "'###'"
   ]
  },
  {
   "cell_type": "code",
   "id": "85549f9b04c53ac9",
   "metadata": {},
   "source": [
    "from sklearn.metrics import '###'\n",
    "\n",
    "# Need to keep these lines to be able to use numpy and the evaluation metrics \n",
    "# Convert tensors to numpy\n",
    "y_test_class_np = y_test_class.detach().numpy()\n",
    "y_pred_class_np = y_pred_class.detach().numpy()\n",
    "\n",
    "# Classification metrics\n",
    "print(\"Accuracy:\", ###)\n",
    "print(\"Precision:\",###)\n",
    "print(\"Recall:\", ###)\n",
    "print(\"F1 Score:\", ###)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "96bd339d39863f3e",
   "metadata": {},
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_class_np, y_test_pred.detach().numpy())\n",
    "auc_score = roc_auc_score(y_test_class_np, y_pred_class_np)\n",
    "plt.plot(fpr, tpr, label=f'Area under ROC curve = {auc_score:.3f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c5336bbb413b732",
   "metadata": {},
   "source": [
    "### 12) Is this AUC better than random? Is it perfect?\n",
    "\n",
    "*12607: 1 point , 12707: 1 point* \n",
    "\n",
    "\n",
    "'###'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9e79e1b090fc07",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
