{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryan-albelda/Ralbelda_CMU_12707_HW/blob/main/Homework_4/HW4_12607_12707_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f5d63bf29b7954a",
      "metadata": {
        "id": "2f5d63bf29b7954a"
      },
      "source": [
        "# Homework 4: 12707 and 12607\n",
        "\n",
        "Homework created by Ryan Albelda"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1bba30056609e80",
      "metadata": {
        "id": "f1bba30056609e80"
      },
      "source": [
        "Homework 4: Please adjust where you see the '###'. Short answers and adjustments to code is required.\n",
        "\n",
        "#### Note/Hint: To get full credit on the short answer, relate answers back to this dataset.\n",
        "\n",
        "\n",
        "*We want to give you as many points as possible*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9de99e2fee58db72",
      "metadata": {
        "id": "9de99e2fee58db72"
      },
      "source": [
        "#### About the Data Set:\n",
        "\n",
        "Access to potable water is essential for human survival and various uses, but laboratory assessments for water quality can be challenging to comply with. This work addresses the issue by creating datasets for drinking and irrigation water to train machine learning models, which offer a viable and cost-effective alternative to lab-based assessments.\n",
        "\n",
        "A pdf about the dataset is provided in the zip file\n",
        "\n",
        "Olasupo Ajayi, Antoine Bagula, Hloniphani Maluleke. (2022). Dataset for Assessing Water Quality for Drinking and Irrigation Purposes using Machine Learning Models. IEEE Dataport. https://dx.doi.org/10.21227/trcf-1s03"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ee1aae0f5d569fd",
      "metadata": {
        "id": "1ee1aae0f5d569fd"
      },
      "source": [
        "# Part 1: Name, Homework Objectives, Classification Type\n",
        "\n",
        "12707: 11 points, 12607: 14.5 points"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abb307595df26bb4",
      "metadata": {
        "id": "abb307595df26bb4"
      },
      "source": [
        "### 1) Name, Andrew ID, and time to complete the homework\n",
        "'###'"
      ]
    },
    {
      "metadata": {
        "id": "b39ef80786f7b694"
      },
      "cell_type": "markdown",
      "source": [
        "*answer here*"
      ],
      "id": "b39ef80786f7b694"
    },
    {
      "cell_type": "markdown",
      "id": "cb7b1ce30c098a32",
      "metadata": {
        "id": "cb7b1ce30c098a32"
      },
      "source": [
        "### Homework Objectives\n",
        "\n",
        "1. **Understand key statistical tools used in climate data analysis**  \n",
        "   - Learn how to calculate and interpret the **Pearson correlation coefficient** to assess linear relationships  \n",
        "   - Understand how the **R-squared value** explains model fit in linear regression  \n",
        "   - Explore the meaning and use of **Mean Squared Error (MSE)** as a model accuracy metric  \n",
        "\n",
        "2. **Load and prepare climate datasets for analysis**  \n",
        "   - Load historical **CO₂ emissions** and **sea level rise** data from CSV files using pandas  \n",
        "   - Convert columns to appropriate data types (e.g., parse year columns to datetime format)  \n",
        "   - Clean and extract relevant columns such as year, sea level change, and emissions values  \n",
        "\n",
        "3. **Align and combine datasets based on overlapping time periods**  \n",
        "   - Use pandas filtering to isolate matching years in both datasets  \n",
        "   - Create a combined dataframe to support consistent time series analysis  \n",
        "\n",
        "4. **Visualize climate trends using plots**  \n",
        "   - Plot sea level rise and CO₂ emissions over time with proper labels and units  \n",
        "   - Create scatter plots to compare emissions to sea level rise  \n",
        "   - Add grid lines, trend lines, and customized titles to improve plot readability  \n",
        "\n",
        "5. **Apply linear regression modeling to explore climate relationships**  \n",
        "   - Fit a linear model using scikit-learn’s `LinearRegression` class  \n",
        "   - Plot the regression line alongside raw data to visualize the fit  \n",
        "   - Use correlation metrics to validate relationships observed in the plots  \n",
        "\n",
        "6. **Evaluate regression model performance**  \n",
        "   - Compute **R-squared** to measure explained variance in the target variable  \n",
        "   - Calculate **MSE** to quantify prediction errors  \n",
        "   - Compare results before and after fitting the model to determine improvement  \n",
        "\n",
        "7. **Test a segmented modeling approach for improved accuracy**  \n",
        "   - Split the dataset into two ranges based on a CO₂ threshold (e.g., 10,000 MtCO₂)  \n",
        "   - Fit separate linear models to each range and compare performance metrics  \n",
        "   - Justify the segmentation approach using visual and statistical evidence  \n",
        "\n",
        "8. **Interpret model results and discuss limitations**  \n",
        "   - Reflect on what statistical metrics reveal about model accuracy and bias  \n",
        "   - Evaluate if splitting the data leads to meaningful improvement  \n",
        "   - Summarize limitations of the linear model and propose next steps for better modeling  \n"
      ]
    },
    {
      "metadata": {
        "id": "8f5f8318510f960d"
      },
      "cell_type": "markdown",
      "source": [
        "Change this cell to be code and import packages:\n",
        "* `import pandas as pd`\n",
        "* `import numpy as np`\n",
        "* `import matplotlib.pyplot as plt`\n",
        "* `import seaborn as sns`"
      ],
      "id": "8f5f8318510f960d"
    },
    {
      "metadata": {
        "id": "99f78efcb7a7e216"
      },
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "id": "99f78efcb7a7e216",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8c17ae5f62a7334c"
      },
      "cell_type": "markdown",
      "source": [
        "Read in `DrinkingWater_Final_Dataset.csv` using pandas\n",
        "* The remainder of the code references the data as 'df_drinking'"
      ],
      "id": "8c17ae5f62a7334c"
    },
    {
      "metadata": {
        "id": "442b9fe2f247b0a4"
      },
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "id": "442b9fe2f247b0a4",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "a85ecee4ca846ade"
      },
      "cell_type": "markdown",
      "source": [
        "Explore the data set to understand the variables.In the zip file is documentation about the dataset.\n",
        "\n",
        "Some suggestions to explore the dataset:\n",
        "* df.head()\n",
        " * df.describe()\n",
        "  * df.info()\n",
        "  * df.tail()"
      ],
      "id": "a85ecee4ca846ade"
    },
    {
      "metadata": {
        "id": "cd6b510fdcf75dca"
      },
      "cell_type": "markdown",
      "source": [
        "### 2) Classifier Type\n",
        "\n",
        " #### A classifier is a type of machine learning algorithm used to assign a class label to a data input. This data set (Drinking Water Data) is an example of a binary classifier. The Iris dataset (seen in class) is a multi-class classifier. Explain what the difference between binary classifier and multi-class classifier. Do this in two sentences.  \n",
        "\n",
        "Iris data to view and explore:\n",
        "\n",
        "* Iris dataset: https://archive.ics.uci.edu/dataset/53/iris\n",
        "\n",
        "* `from sklearn.datasets import load_iris; iris = load_iris()`\n",
        "\n",
        "\n",
        "\n",
        "'###'"
      ],
      "id": "cd6b510fdcf75dca"
    },
    {
      "cell_type": "markdown",
      "id": "824e604db6c6f063",
      "metadata": {
        "id": "824e604db6c6f063"
      },
      "source": [
        "*answer here* --> Only grading the final answer, feel free to use your own method to figure this out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7d7a42628c3d826",
      "metadata": {
        "id": "e7d7a42628c3d826"
      },
      "source": [
        "### Lets explore a machine learning (ML) method to try to do the classification..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867ac3f524db5d7e",
      "metadata": {
        "id": "867ac3f524db5d7e"
      },
      "source": [
        "# Part 2: K-nearest neighbors (KNN)\n",
        "12707: 36 points, 12607: 24 points\n",
        "\n",
        "12607:Skip question 9\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3378092c68f8731f",
      "metadata": {
        "id": "3378092c68f8731f"
      },
      "source": [
        "#### What is KNN: \"The k-nearest neighbors (KNN) algorithm is supervised learning classifier. It uses proximity to make classifications or predictions about the grouping of an individual data point.\"\n",
        "\n",
        "What is the k-nearest neighbors algorithm? | IBM. (2021, October 4). https://www.ibm.com/think/topics/knn\n",
        "\n",
        "\n",
        "\n",
        "Extra video to help explain KNN: https://www.youtube.com/watch?v=HVXime0nQeI\n",
        "    (StatQuest with Josh Starmer, 2017)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aa9b630d76c679c",
      "metadata": {
        "id": "4aa9b630d76c679c"
      },
      "source": [
        "![title](KNN image.png)\n",
        "\n",
        "The above image is an example of how knn works"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d638e96daff0f57e",
      "metadata": {
        "id": "d638e96daff0f57e"
      },
      "source": [
        "### 3) Let's explore variables to see if we learn more about them. What is the range of pH for drinking water?\n",
        "\n",
        "#### This will help us in the code to create classes and explore knn\n",
        "\n",
        "Write code to find the range of pH values.\n",
        "* Hint `numpy` has a `max` and a `min` feature\n",
        "\n",
        "'###'"
      ]
    },
    {
      "metadata": {
        "id": "213d01b81dda874b"
      },
      "cell_type": "code",
      "source": [
        "#code here"
      ],
      "id": "213d01b81dda874b",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "2ff10c4b1f75293d",
      "metadata": {
        "id": "2ff10c4b1f75293d"
      },
      "source": [
        "### 4) Plot the pH value vs the Water Quality Index (WQI).\n",
        "##### Set a unique color for each of the first number of the pH.\n",
        "\n",
        "##### 12607 skip and check email for the code\n",
        "\n",
        "Starter code is provided\n",
        "\n",
        "\n",
        "'###'\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "66bf6160e1bd6055",
      "metadata": {
        "scrolled": true,
        "id": "66bf6160e1bd6055"
      },
      "source": [
        "# Check if 'pH' and 'WQI' exist in the dataset\n",
        "if 'pH' in df_drinking.columns and 'WQI' in df_drinking.columns:\n",
        "    # Extract unique pH values and assign a color to each unique first decimal digit of pH\n",
        "    df_drinking['pH_rounded'] = df_drinking['pH'].apply(lambda x: str(x)[0])\n",
        "    # Get the first digit of pH\n",
        "\n",
        "    # Create scatter plot\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.scatterplot(data=df_drinking, x='###', y='###',\n",
        "                    hue='pH_rounded', palette=\"tab10\", alpha=0.7)\n",
        "\n",
        "    # Labels and title\n",
        "    plt.xlabel(\"###\")\n",
        "    plt.ylabel(\"###\")\n",
        "    plt.title(\"pH vs. WQI with Colors Based on First Digit of pH\")\n",
        "    plt.legend(title=\"###\")\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"The columns 'pH' and 'WQI' are not present in the Drinking Water dataset.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "b9bdec0a62a52f32",
      "metadata": {
        "id": "b9bdec0a62a52f32"
      },
      "source": [
        "### 5) Are the data points clustered around a single ph value? (Y/N)\n",
        "\n",
        "\n",
        "##### The goal of this question is to start to think about clusters of data. KNN a works to classify data based on clusters.\n",
        "\n",
        "This dataset is NOT the best to show these clusters. To better explore this concept, we will use the Iris dataset.\n"
      ]
    },
    {
      "metadata": {
        "id": "a53532a3e5d2eb50"
      },
      "cell_type": "markdown",
      "source": [
        "*answer here*"
      ],
      "id": "a53532a3e5d2eb50"
    },
    {
      "cell_type": "markdown",
      "id": "27a3be7fd5a05d6f",
      "metadata": {
        "id": "27a3be7fd5a05d6f"
      },
      "source": [
        "### Let's revisit the Iris dataset to provide a clear example of the K-Nearest Neighbors (KNN) algorithm before applying it to our dataset."
      ]
    },
    {
      "metadata": {
        "id": "c92ad11f93dd2b9c"
      },
      "cell_type": "code",
      "source": [
        "# Load the iris dataset\n",
        "iris = sns.load_dataset('iris')\n",
        "\n",
        "print(iris.head())"
      ],
      "id": "c92ad11f93dd2b9c",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "5d23ed3775e9aed4",
      "metadata": {
        "id": "5d23ed3775e9aed4"
      },
      "source": [
        "#### Run the following code to plot the relationship between Petal Width vs Petal Length\n",
        "\n",
        "##### Two points from the data are selected to be used for species type prediction via classification. These points are labeled a star and diamond."
      ]
    },
    {
      "cell_type": "code",
      "id": "7f7f4b856b222e02",
      "metadata": {
        "id": "7f7f4b856b222e02"
      },
      "source": [
        "point_star = iris.iloc[(iris[['petal_length', 'petal_width']] -\n",
        "                        [5.0, 1.5]).abs().sum(axis=1).idxmin()]\n",
        "point_diamond = iris.iloc[(iris[['petal_length', 'petal_width']] -\n",
        "                           [6.5, 3.3]).abs().sum(axis=1).idxmin()]\n",
        "\n",
        "\n",
        "# Plot petal width vs petal length\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(\n",
        "    x='petal_length',\n",
        "    y='petal_width',\n",
        "    hue='species',   # Color by species\n",
        "    palette='viridis',  # You can change this to any color palette\n",
        "    data=iris\n",
        ")\n",
        "\n",
        "\n",
        "plt.scatter(\n",
        "    x=point_star['petal_length'],\n",
        "    y=point_star['petal_width'],\n",
        "    color='black',\n",
        "    marker='*',\n",
        "    s=200,\n",
        "    label='Star Point'\n",
        ")\n",
        "plt.scatter(\n",
        "    x=point_diamond['petal_length'],\n",
        "    y=point_diamond['petal_width'],\n",
        "    color='purple',\n",
        "    marker='D',\n",
        "    s=100,\n",
        "    label='Diamond Point'\n",
        ")\n",
        "# Add labels and title\n",
        "plt.title('Petal Width vs Petal Length')\n",
        "plt.xlabel('Petal Length (cm)')\n",
        "plt.ylabel('Petal Width (cm)')\n",
        "plt.legend(title='Species')\n",
        "plt.grid(True)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n",
        "\n",
        "# code created by Chat GPT"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "26679b625e6cfd7b",
      "metadata": {
        "id": "26679b625e6cfd7b"
      },
      "source": [
        "### 6) Which elementary shape (diamond or star) can be easily classified as Virginica? Additionally, which shape presents ambiguity in determining the flower type?\n",
        "\n",
        "\n",
        "'###'"
      ]
    },
    {
      "metadata": {
        "id": "fe90d462ac33fb85"
      },
      "cell_type": "markdown",
      "source": [
        "*answer here*"
      ],
      "id": "fe90d462ac33fb85"
    },
    {
      "cell_type": "markdown",
      "id": "f543a9acce049752",
      "metadata": {
        "id": "f543a9acce049752"
      },
      "source": [
        "#### Same process again and comparing another set of variables: Run the following code to plot the relationship between Sepal Width vs Petal Width\n",
        "\n",
        "Two different points from the data are selected to be used for species type prediction via classification. These points are labeled a star and diamond."
      ]
    },
    {
      "cell_type": "code",
      "id": "41d293d03c9cf549",
      "metadata": {
        "id": "41d293d03c9cf549"
      },
      "source": [
        "# Find points to highlight\n",
        "point_star = iris.iloc[(iris[['sepal_width', 'petal_width']] -\n",
        "                        [3.0, 1.6]).abs().sum(axis=1).idxmin()]\n",
        "point_diamond = iris.iloc[(iris[['sepal_width', 'petal_width']] -\n",
        "                           [3.0, 0.3]).abs().sum(axis=1).idxmin()]\n",
        "\n",
        "# Plot sepal width vs petal width\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(\n",
        "    x='sepal_width',\n",
        "    y='petal_width',\n",
        "    hue='species',\n",
        "    palette='Set1',\n",
        "    data=iris\n",
        ")\n",
        "\n",
        "# Overlay star marker (point near 3.0, 1.6)\n",
        "plt.scatter(\n",
        "    x=point_star['sepal_width'],\n",
        "    y=point_star['petal_width'],\n",
        "    color='black',\n",
        "    marker='*',\n",
        "    s=200,\n",
        "    label='Star Point'\n",
        ")\n",
        "\n",
        "# Overlay diamond marker (point near 3.0, 0.3)\n",
        "plt.scatter(\n",
        "    x=point_diamond['sepal_width'],\n",
        "    y=point_diamond['petal_width'],\n",
        "    color='purple',\n",
        "    marker='D',\n",
        "    s=100,\n",
        "    label='Diamond Point'\n",
        ")\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Sepal Width vs Petal Width')\n",
        "plt.xlabel('Sepal Width (cm)')\n",
        "plt.ylabel('Petal Width (cm)')\n",
        "plt.legend(title='Species', loc='upper left')\n",
        "plt.grid(True)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n",
        "\n",
        "# code created by Chat GPT"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "ceadd37b707fafb5",
      "metadata": {
        "id": "ceadd37b707fafb5"
      },
      "source": [
        "Here the diamond shape is classified as setosa. The star point is not clear."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d93d324ae8c5b9c7",
      "metadata": {
        "id": "d93d324ae8c5b9c7"
      },
      "source": [
        "### Returning to the water dataset:\n",
        "##### Do KNN for Magnesium vs Calcium with Potability\n",
        "\n",
        "* Potable samples are marked with an 'X'\n",
        "* Not Potable samples are marked with an 'o'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "25930830068cade8",
      "metadata": {
        "id": "25930830068cade8"
      },
      "source": [
        "# Make sure the necessary columns exist\n",
        "if {'Magnesium', 'Calcium', 'Potability'}.issubset(df_drinking.columns):\n",
        "\n",
        "    # Set marker shapes for potable and non-potable\n",
        "    markers = {0: 'o', 1: 'x'}  # 'o' for not potable, 'x' for potable\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Loop through potability levels and plot with different markers\n",
        "    for potability, marker in markers.items():\n",
        "        subset = df_drinking[df_drinking['Potability'] == potability]\n",
        "        plt.scatter(subset['Magnesium'], subset['Calcium'],\n",
        "                    label=f'Potability = {potability}',\n",
        "                    marker=marker, alpha=0.7)\n",
        "\n",
        "    # Labels, legend, and grid\n",
        "    plt.xlabel('Magnesium')\n",
        "    plt.ylabel('Calcium')\n",
        "    plt.title('Magnesium vs Calcium with Potability as Different Shapes')\n",
        "    plt.legend(title='Potability')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"The columns 'Magnesium', 'Calcium', and \"\n",
        "          \"'Potability' are required in the dataset.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "4d18f4b2a5d6d4e9",
      "metadata": {
        "id": "4d18f4b2a5d6d4e9"
      },
      "source": [
        "##### Run the code again. Zoom in on the axsis.\n",
        "\n",
        "###### Set the range for Magnesium and Calcium to be from 0 to 100\n",
        "    plt.xlim(0, 100)\n",
        "    plt.ylim(0, 100)"
      ]
    },
    {
      "cell_type": "code",
      "id": "694ad7080bb4d443",
      "metadata": {
        "id": "694ad7080bb4d443"
      },
      "source": [
        "# Make sure the necessary columns exist\n",
        "if {'Magnesium', 'Calcium', 'Potability'}.issubset(df_drinking.columns):\n",
        "\n",
        "    # Set marker shapes for potable and non-potable\n",
        "    markers = {0: 'o', 1: 'x'}  # 'o' for not potable, 'x' for potable\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Loop through potability levels and plot with different markers\n",
        "    for potability, marker in markers.items():\n",
        "        subset = df_drinking[df_drinking['Potability'] == potability]\n",
        "        plt.scatter(subset['Magnesium'], subset['Calcium'],\n",
        "                    label=f'Potability = {potability}',\n",
        "                    marker=marker, alpha=0.7)\n",
        "\n",
        "    ### Set the range for Magnesium and Calcium to be from 0 to 100\n",
        "    plt.xlim(0, 100)\n",
        "    plt.ylim(0, 100)\n",
        "\n",
        "    # Labels, legend, and grid\n",
        "    plt.xlabel('Magnesium')\n",
        "    plt.ylabel('Calcium')\n",
        "    plt.title('Magnesium vs Calcium with '\n",
        "              'Potability as Different Shapes')\n",
        "    plt.legend(title='Potability')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"The columns 'Magnesium', 'Calcium', and 'Potability' are required in the dataset.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "218d30ff3f598928"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import the following package to run Knn\n",
        "       \n",
        "    from sklearn.cluster import KMeans"
      ],
      "id": "218d30ff3f598928"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-12T15:42:01.482933Z",
          "start_time": "2025-03-12T15:42:01.480654Z"
        },
        "id": "3cd6a3eeb08b4178"
      },
      "cell_type": "code",
      "source": [
        "#Code here and import package"
      ],
      "id": "3cd6a3eeb08b4178",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "912708258d7b51b",
      "metadata": {
        "id": "912708258d7b51b"
      },
      "source": [
        "# Make sure the necessary columns exist\n",
        "if ({'Magnesium', 'Calcium', 'Potability'}.\n",
        "        issubset(df_drinking.columns)):\n",
        "\n",
        "    # Set marker shapes for potable and non-potable\n",
        "    markers = {0: 'o', 1: 'x'}  # 'o' for not potable, 'x' for potable\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Loop through potability levels and plot with different markers\n",
        "    for potability, marker in markers.items():\n",
        "        subset = df_drinking[df_drinking['Potability'] == potability]\n",
        "        plt.scatter(subset['Magnesium'], subset['Calcium'],\n",
        "                    label=f'Potability = {potability}',\n",
        "                    marker=marker, alpha=0.7)\n",
        "\n",
        "##doing K means clustering\n",
        "    kmeans = KMeans(n_clusters= 20)\n",
        "    df_drinking['Cluster'] = (kmeans.fit_predict\n",
        "                              (df_drinking[['Magnesium', 'Calcium']])) ## predicting if save to drink\n",
        "\n",
        "    # Plot larger circles around cluster centers\n",
        "    centers = kmeans.cluster_centers_\n",
        "    for center in centers:\n",
        "        plt.scatter(center[0], center[1], s=2000, c='red', alpha=0.3, edgecolors='black')\n",
        "\n",
        "    # Labels, legend, and grid\n",
        "    plt.xlabel('Magnesium')\n",
        "    plt.ylabel('Calcium')\n",
        "    plt.title('Magnesium vs Calcium with Potability as Different Shapes and KMeans Clusters')\n",
        "    plt.legend(title='Potability')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"The columns 'Magnesium', 'Calcium', and 'Potability' are required in the dataset.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "a37433bf3c8564a",
      "metadata": {
        "id": "a37433bf3c8564a"
      },
      "source": [
        "### Predicting potability with fewer clusters\n",
        "##### Question 7 is located in the code and below the script\n",
        "\n",
        "In this exercise, you will analyze how changing the number of clusters in K-Means affects the grouping of data points in a scatter plot.\n",
        "\n",
        "1. Run the provided code to generate the scatter plot, which includes K-Means clusters and potable/non-potable water distinctions.\n",
        "2. Modify the number of clusters (n_clusters) in the KMeans function to different values (e.g., 3, 5, 8, 13) and observe how the cluster locations and boundaries change."
      ]
    },
    {
      "cell_type": "code",
      "id": "875341f46a883dda",
      "metadata": {
        "id": "875341f46a883dda"
      },
      "source": [
        "# Make sure the necessary columns exist\n",
        "if {'Magnesium', 'Calcium', 'Potability'}.issubset(df_drinking.columns):\n",
        "\n",
        "    # Set marker shapes for potable and non-potable\n",
        "    markers = {0: 'o', 1: 'x'}  # 'o' for not potable, 'x' for potable\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Loop through potability levels and plot with different markers\n",
        "    for potability, marker in markers.items():\n",
        "        subset = df_drinking[df_drinking['Potability'] == potability]\n",
        "        plt.scatter(subset['Magnesium'], subset['Calcium'],\n",
        "                    label=f'Potability = {potability}',\n",
        "                    marker=marker, alpha=0.7)\n",
        "\n",
        "### 7) Change total cluster numbers and explain what is going on\n",
        "    # Perform KMeans clustering\n",
        "    kmeans = KMeans(n_clusters= 1)\n",
        "    ### Change cluster numbers\n",
        "    df_drinking['Cluster'] = kmeans.fit_predict(df_drinking[['Magnesium', 'Calcium']])\n",
        "\n",
        "    # Plot larger circles around cluster centers\n",
        "    centers = kmeans.cluster_centers_\n",
        "    for center in centers:\n",
        "        plt.scatter(center[0], center[1], s=2000, c='red', alpha=0.3, edgecolors='black')\n",
        "    # Set the x and y axes to be on a log scale\n",
        "    plt.xscale('log')\n",
        "    plt.yscale('log')\n",
        "\n",
        "    # Labels, legend, and grid\n",
        "    plt.xlabel('Magnesium')\n",
        "    plt.ylabel('Calcium')\n",
        "    plt.title('Magnesium vs Calcium with Potability as Different Shapes and KMeans Clusters')\n",
        "    plt.legend(title='Potability')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"The columns 'Magnesium', 'Calcium', and 'Potability' are required in the dataset.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "a8af6ed244e174b8",
      "metadata": {
        "id": "a8af6ed244e174b8"
      },
      "source": [
        "### 7) Does increasing the number of clusters perfectly capture all of data? Do certain cluster numbers create more exact groupings based on potability? Why or why not? Answer in 2-3 sentences\n",
        "\n",
        "\n",
        "Note: a log scale is applied to enhance data visibility. Change scale as needed to answer questions\n",
        "\n",
        "'###'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "306d8cb736772448",
      "metadata": {
        "id": "306d8cb736772448"
      },
      "source": [
        "*answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "640ea2b6e21d2756",
      "metadata": {
        "id": "640ea2b6e21d2756"
      },
      "source": [
        "\n",
        "### 8)This dataset contains a total of 718 samples. Would it be beneficial or problematic to use 600  total clusters for this dataset in K-Means clustering?\n",
        "\n",
        "   * Provide at least two reasons to support your answer to receive full credit.\n",
        "   * Consider both the advantages and disadvantages of having a high number of clusters.\n",
        "   * Think about interpretability, overfitting, and the purpose of clustering in your response.\n",
        "     \n",
        "*some research/exploration may help answer this question*\n",
        "\n",
        "'###'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fe401306ae4a623",
      "metadata": {
        "id": "6fe401306ae4a623"
      },
      "source": [
        "*answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ececb328ecbba585",
      "metadata": {
        "id": "ececb328ecbba585"
      },
      "source": [
        "### No points: Just to think about\n",
        "\n",
        "#### Do you think there is rule of thumb for how many clusters to use? What if our data was trying to decipher letters of the alphabet (think about number of letters)?\n"
      ]
    },
    {
      "metadata": {
        "id": "66fd1d6189de7bca"
      },
      "cell_type": "markdown",
      "source": [
        "#### The elbow method is a popular heuristic to finding the optimal number of clusters. The graph appears to have a bend like a elbow. This bending point notes where adding more clusters provides diminishing returns in terms of improved data fit."
      ],
      "id": "66fd1d6189de7bca"
    },
    {
      "cell_type": "markdown",
      "id": "fe75da2ba948db61",
      "metadata": {
        "id": "fe75da2ba948db61"
      },
      "source": [
        " ### Running the heuristic to find the ideal cluster number\n",
        " the package: from sklearn.cluster import KMeans is required to run this\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "19f9c869777117e5",
      "metadata": {
        "id": "19f9c869777117e5"
      },
      "source": [
        "# Make sure the necessary columns exist\n",
        "if {'Magnesium', 'Calcium', 'Potability'}.issubset(df_drinking.columns):\n",
        "\n",
        "    # =========================\n",
        "    # Elbow Method Calculation\n",
        "    # =========================\n",
        "\n",
        "    # Use only Magnesium and Calcium for clustering\n",
        "    X = df_drinking[['Magnesium', 'Calcium']]\n",
        "\n",
        "    # Calculate WCSS for k values 1 to 15\n",
        "    wcss = []\n",
        "    for k in range(1, 16):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "        kmeans.fit(X)\n",
        "        wcss.append(kmeans.inertia_)  # Inertia is the sum of\n",
        "        # squared distances to nearest cluster center\n",
        "\n",
        "    # Plot the elbow curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, 16), wcss, marker='o', linestyle='--')\n",
        "    plt.title('Elbow Method - Optimal k')\n",
        "    plt.xlabel('Number of Clusters (k)')\n",
        "    plt.ylabel('WCSS (Within-cluster sum of squares)')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # =========================\n",
        "    # Cluster Plotting\n",
        "    # =========================\n",
        "\n",
        "### 9) Change based on best value\n",
        "    # You can update 'n_clusters' based on the elbow plot\n",
        "    optimal_k = 9  ### Replace with the optimal k you observe from the elbow curve\n",
        "\n",
        "    # Set marker shapes for potable and non-potable\n",
        "    markers = {0: 'o', 1: 'x'}  # 'o' for not potable, 'x' for potable\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Loop through potability levels and plot with different markers\n",
        "    for potability, marker in markers.items():\n",
        "        subset = df_drinking[df_drinking['Potability'] == potability]\n",
        "        plt.scatter(subset['Magnesium'], subset['Calcium'],\n",
        "                    label=f'Potability = {potability}',\n",
        "                    marker=marker, alpha=0.7)\n",
        "\n",
        "    # Perform KMeans clustering with optimal k\n",
        "    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "    df_drinking['Cluster'] = kmeans.fit_predict(df_drinking[\n",
        "                                                    ['Magnesium', 'Calcium']])\n",
        "\n",
        "    # Plot larger circles around cluster centers\n",
        "    centers = kmeans.cluster_centers_\n",
        "    for center in centers:\n",
        "        plt.scatter(center[0], center[1], s=2000, c='red', alpha=0.3,\n",
        "                    edgecolors='black')\n",
        "\n",
        "\n",
        "\n",
        "    # Labels, legend, and grid\n",
        "    plt.xlabel('Magnesium')\n",
        "    plt.ylabel('Calcium')\n",
        "    plt.title(f'Magnesium vs Calcium with Potability and KMeans '\n",
        "              f'(k={optimal_k}) Clusters')\n",
        "    plt.legend(title='Potability')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"The columns 'Magnesium', 'Calcium', and 'Potability' are required in the dataset.\")\n",
        "\n",
        "#Code from Chat GPT"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "bf3d7c9a8d3a0ab5",
      "metadata": {
        "id": "bf3d7c9a8d3a0ab5"
      },
      "source": [
        "### 9) What was the best fitting number of cluster for this data? Does this make sense? Think about what we are trying to classify.  \n",
        "##### 12607: Skip\n",
        "\n",
        "Hint: see what value the elbow method suggests for the Iris data below\n",
        "\n",
        "'###'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4be988a4df33cf6",
      "metadata": {
        "id": "4be988a4df33cf6"
      },
      "source": [
        "\n",
        "*answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef15064e9eee88be",
      "metadata": {
        "id": "ef15064e9eee88be"
      },
      "source": [
        "### Demonstrating the Elbow Method with the Iris Dataset\n",
        "\n",
        "To further illustrate this concept, we apply the elbow method to the Iris dataset as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "276cd7122ca843c4",
      "metadata": {
        "id": "276cd7122ca843c4"
      },
      "source": [
        "#DONT CHANGE THIS CODE\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load iris dataset\n",
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "\n",
        "# Use only 'sepal length' and 'sepal width' for clustering\n",
        "X = df_iris[['sepal length (cm)', 'sepal width (cm)']]\n",
        "\n",
        "# =========================\n",
        "# Elbow Method Calculation\n",
        "# =========================\n",
        "\n",
        "# Calculate WCSS for k values 1 to 15\n",
        "wcss = []\n",
        "for k in range(1, 16):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X)\n",
        "    wcss.append(kmeans.inertia_)  # Inertia is the sum of squared\n",
        "    # distances to nearest cluster center\n",
        "\n",
        "# Plot the elbow curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 16), wcss, marker='o', linestyle='--')\n",
        "plt.title('Elbow Method - Optimal k')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('WCSS (Within-cluster sum of squares)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# =========================\n",
        "# Cluster Plotting\n",
        "# =========================\n",
        "\n",
        "optimal_k = 3  # This is often 3 for Iris,\n",
        "\n",
        "# Perform KMeans clustering with optimal k\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "df_iris['Cluster'] = kmeans.fit_predict(X)\n",
        "\n",
        "# Plot the clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "for cluster in range(optimal_k):\n",
        "    subset = df_iris[df_iris['Cluster'] == cluster]\n",
        "    plt.scatter(subset['sepal length (cm)'], subset['sepal width (cm)'],\n",
        "                label=f'Cluster {cluster}', alpha=0.7)\n",
        "\n",
        "# Plot larger circles around cluster centers\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], s=300, c='red', marker='X',\n",
        "            edgecolors='black', label='Center of Clusters')\n",
        "\n",
        "# Labels, legend, and grid\n",
        "plt.xlabel('Sepal Length (cm)')\n",
        "plt.ylabel('Sepal Width (cm)')\n",
        "plt.title(f'Sepal Length vs Sepal Width with KMeans (k={optimal_k}) Clusters')\n",
        "plt.legend(title='Cluster')\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "#Code from Chat GPT"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "49c6aa2c5394f4a6",
      "metadata": {
        "id": "49c6aa2c5394f4a6"
      },
      "source": [
        "\n",
        "### Moving to another ML method"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "278519814240587e",
      "metadata": {
        "id": "278519814240587e"
      },
      "source": [
        "# Part 3: Support Vector Machines\n",
        "12707: 7 points, 12607: 9 points"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b740dff65dd5960",
      "metadata": {
        "id": "b740dff65dd5960"
      },
      "source": [
        "What is a Support Vector Machine (SVM)?\n",
        "\n",
        "\"A support vector machine (SVM) is a supervised machine learning algorithm that classifies data by finding an optimal line or hyperplane that maximizes the distance between each class in an N-dimensional space.\"\n",
        "\n",
        "What Is Support Vector Machine? | IBM. (2023, December 12). https://www.ibm.com/think/topics/support-vector-machine\n",
        "\n",
        "Extra Video to explain SVM: https://www.youtube.com/watch?v=_YPScrckx28\n",
        "(Visually Explained, 2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae2fbcf4915c7d74",
      "metadata": {
        "id": "ae2fbcf4915c7d74"
      },
      "source": [
        "\n",
        "![title](SVM image.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c04cb8373f72903",
      "metadata": {
        "id": "6c04cb8373f72903"
      },
      "source": [
        "### Lets explore this with our data: We can look at pH and water quality to see if the water is potable. We will solve for some unknown points\n",
        "\n",
        "The star points are what we are going to try to solve and predict"
      ]
    },
    {
      "cell_type": "code",
      "id": "55389e7870bb8ea",
      "metadata": {
        "id": "55389e7870bb8ea"
      },
      "source": [
        "# Check if 'WQI', 'pH', and 'Potability' exist in the Drinking Water dataset\n",
        "if {'WQI', 'pH', 'Potability'}.issubset(df_drinking.columns):\n",
        "    # Scatter plot for pH vs. WQI with color based on Potability\n",
        "    plt.figure(figsize=(8, 5))\n",
        "\n",
        "    # Plot Potability = 1 in one color and Potability = 0 in another\n",
        "    plt.scatter(df_drinking[df_drinking['Potability'] == 1]['pH'],\n",
        "                df_drinking[df_drinking['Potability'] == 1]['WQI'],\n",
        "                color='blue', label=\"Potable (1)\", alpha=0.6, marker = 'x')\n",
        "\n",
        "    plt.scatter(df_drinking[df_drinking['Potability'] == 0]['pH'],\n",
        "                df_drinking[df_drinking['Potability'] == 0]['WQI'],\n",
        "                color='red', label=\"Not Potable (0)\", alpha=0.6)\n",
        "    df_star = df_drinking[(df_drinking['WQI'] >= 49.5) & (df_drinking['WQI'] <= 51)]\n",
        "\n",
        "    plt.scatter(df_star['pH'],\n",
        "            df_star['WQI'],\n",
        "            color='black', label=\"Unknown Points\",\n",
        "            marker='*', s=200)  # s=200 makes the star larger\n",
        "\n",
        "    # Labels and title\n",
        "    plt.xlabel(\"pH Value\")\n",
        "    plt.ylabel(\"Water Quality Index (WQI)\")\n",
        "    plt.title(\"pH vs. WQI with Potability\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"The columns 'WQI', 'pH', and 'Potability' are not \"\n",
        "          \"present in the Drinking Water dataset.\")\n",
        "#Code from Chat GPT"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "9a46778c40e00983",
      "metadata": {
        "id": "9a46778c40e00983"
      },
      "source": [
        "### Sort of looks like a line, between the data lets keep zooming in\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "2d48e9cc273a3ba8",
      "metadata": {
        "id": "2d48e9cc273a3ba8"
      },
      "source": [
        "# Check if 'WQI', 'pH', and 'Potability' exist in the Drinking Water dataset\n",
        "if {'WQI', 'pH', 'Potability'}.issubset(df_drinking.columns):\n",
        "    # Scatter plot for pH vs. WQI with color based on Potability, using log scale for WQI\n",
        "    plt.figure(figsize=(8, 5))\n",
        "\n",
        "    # Plot Potability = 1 in one color and Potability = 0 in another\n",
        "    plt.scatter(df_drinking[df_drinking['Potability'] == 1]['pH'],\n",
        "                df_drinking[df_drinking['Potability'] == 1]['WQI'],\n",
        "                color='blue', label=\"Potable (1)\",\n",
        "                alpha=0.6, marker = 'x')\n",
        "\n",
        "    plt.scatter(df_drinking[df_drinking['Potability'] == 0]['pH'],\n",
        "                df_drinking[df_drinking['Potability'] == 0]['WQI'],\n",
        "                color='red', label=\"Not Potable (0)\",\n",
        "                alpha=0.6)\n",
        "\n",
        "    df_star = df_drinking[(df_drinking['WQI'] >= 49.5) &\n",
        "                          (df_drinking['WQI'] <= 51)]\n",
        "\n",
        "    plt.scatter(df_star['pH'],\n",
        "            df_star['WQI'],\n",
        "            color='black', label=\"Unknown Points\",\n",
        "            marker='*', s=200)  # s=200 makes the star larger\n",
        "\n",
        "    # Set log scale for Y-axis\n",
        "    plt.yscale(\"log\")\n",
        "\n",
        "    # Labels and title\n",
        "    plt.xlabel(\"pH Value\")\n",
        "    plt.ylabel(\"Water Quality Index (WQI) (Log Scale)\")\n",
        "    plt.title(\"pH vs. WQI with Potability (Log Scale)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"The columns 'WQI', 'pH', and 'Potability' are \"\n",
        "          \"not present in the Drinking Water dataset.\")\n",
        "#Code from Chat GPT"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "d467a5abeaa6371f",
      "metadata": {
        "id": "d467a5abeaa6371f"
      },
      "source": [
        "# Filter for zoomed region (pH between 7.2 and 7.8, WQI between 30 and 70)\n",
        "df_zoom = df_drinking[(df_drinking['pH'] >= 7.2) &\n",
        "                      (df_drinking['pH'] <= 7.8) & (df_drinking['WQI'] >= 38)\n",
        "                      & (df_drinking['WQI'] <= 60)]\n",
        "\n",
        "# Scatter plot - zoomed in\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Potable (1)\n",
        "plt.scatter(df_zoom[df_zoom['Potability'] == 1]['pH'],\n",
        "            df_zoom[df_zoom['Potability'] == 1]['WQI'],\n",
        "            color='blue', label=\"Potable (1)\", alpha=0.6, marker='x')\n",
        "\n",
        "# Not Potable (0)\n",
        "plt.scatter(df_zoom[df_zoom['Potability'] == 0]['pH'],\n",
        "            df_zoom[df_zoom['Potability'] == 0]['WQI'],\n",
        "            color='red', label=\"Not Potable (0)\", alpha=0.6)\n",
        "df_star = df_zoom[(df_zoom['WQI'] >= 49.5) & (df_zoom['WQI'] <= 51)]\n",
        "\n",
        "plt.scatter(df_star['pH'],\n",
        "            df_star['WQI'],\n",
        "            color='black', label=\"Unknown Points\",\n",
        "            marker='*', s=200)  # s=200 makes the star larger\n",
        "\n",
        "\n",
        "# Labels and zoomed title\n",
        "plt.xlabel(\"pH Value\")\n",
        "plt.ylabel(\"Water Quality Index (WQI)\")\n",
        "plt.title(\"Zoomed: pH 7.2-7.8 and WQI 38-60\")\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n",
        "\n",
        "#Code from Chat GPT"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "4f107b8171fb65db",
      "metadata": {
        "id": "4f107b8171fb65db"
      },
      "source": [
        "\n",
        "### 10) For the star points, how many can you easily and confidently say you know if the water is potable or not?\n",
        "*not a trick question, the unknown points are where we use SVM*\n",
        "\n",
        "'###'\n"
      ]
    },
    {
      "metadata": {
        "id": "9603ec5f335868fc"
      },
      "cell_type": "markdown",
      "source": [
        "*answer here*"
      ],
      "id": "9603ec5f335868fc"
    },
    {
      "cell_type": "markdown",
      "id": "e79fa9ec5442ba8b",
      "metadata": {
        "id": "e79fa9ec5442ba8b"
      },
      "source": [
        "#### Lets Apply the SVM model"
      ]
    },
    {
      "cell_type": "code",
      "id": "a58110a60d039a52",
      "metadata": {
        "id": "a58110a60d039a52"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Extract features and labels for the zoomed region\n",
        "X = df_zoom[['pH', 'WQI']].values\n",
        "y = df_zoom['Potability'].values\n",
        "\n",
        "# Train SVM\n",
        "svm_model = SVC(kernel='linear', C=1)\n",
        "svm_model.fit(X, y)\n",
        "\n",
        "# Create mesh grid for decision boundary plot\n",
        "x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "y_min, y_max = X[:, 1].min() - 5, X[:, 1].max() + 5\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                     np.linspace(y_min, y_max, 100))\n",
        "\n",
        "# Predict across the grid\n",
        "Z = svm_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Contour plot for decision boundary\n",
        "plt.contourf(xx, yy, Z, alpha=0.3,\n",
        "             cmap=ListedColormap(['red', 'blue']))\n",
        "\n",
        "# Scatter plot - points\n",
        "plt.scatter(df_zoom[df_zoom['Potability'] == 1]['pH'],\n",
        "            df_zoom[df_zoom['Potability'] == 1]['WQI'],\n",
        "            color='blue', label=\"Potable (1)\", marker='x')\n",
        "\n",
        "plt.scatter(df_zoom[df_zoom['Potability'] == 0]['pH'],\n",
        "            df_zoom[df_zoom['Potability'] == 0]['WQI'],\n",
        "            color='red', label=\"Not Potable (0)\", edgecolor='k')\n",
        "\n",
        "df_star = df_zoom[(df_zoom['WQI'] >= 49.5) & (df_zoom['WQI'] <= 51)]\n",
        "\n",
        "plt.scatter(df_star['pH'],\n",
        "            df_star['WQI'],\n",
        "            color='black', label=\"Unknown Points\",\n",
        "            marker='*', s=200)  # s=200 makes the star larger\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"pH Value\")\n",
        "plt.ylabel(\"Water Quality Index (WQI)\")\n",
        "plt.title(\"SVM Decision Boundary (Zoomed: pH 7.2-7.8 and WQI 38-60)\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#Code from chat GPT"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "4aeb53d7f8632108",
      "metadata": {
        "id": "4aeb53d7f8632108"
      },
      "source": [
        "### 11) For the star points, now is it clear (or at least more clear then before), what points are potable?  (Y/N)\n",
        "\n",
        "\n",
        "'###'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cb31e597d981060",
      "metadata": {
        "id": "4cb31e597d981060"
      },
      "source": [
        "*answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4384a745ae455a93",
      "metadata": {
        "id": "4384a745ae455a93"
      },
      "source": [
        "Run SVM for Potassium and Sodium. One can use SVM for any variable combination"
      ]
    },
    {
      "cell_type": "code",
      "id": "97307afeab2ab051",
      "metadata": {
        "id": "97307afeab2ab051"
      },
      "source": [
        "# Check if necessary columns exist\n",
        "required_columns = {'Potassium', 'Sodium', 'Potability'}\n",
        "if not required_columns.issubset(df_drinking.columns):\n",
        "    raise ValueError(f\"Dataset does not contain required \"\n",
        "                     f\"columns: {required_columns - set(df_drinking.columns)}\")\n",
        "\n",
        "# Drop rows with missing values in relevant columns\n",
        "df_drinking = df_drinking[['Potassium', 'Sodium', 'Potability']].dropna()\n",
        "\n",
        "# Prepare features (X) and labels (y)\n",
        "X = df_drinking[['Potassium', 'Sodium']].values\n",
        "y = df_drinking['Potability'].values\n",
        "\n",
        "# Train SVM with linear kernel\n",
        "svm_model = SVC(kernel='linear', C=1)\n",
        "svm_model.fit(X, y)\n",
        "\n",
        "# Create mesh grid for decision boundary\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                     np.linspace(y_min, y_max, 100))\n",
        "\n",
        "# Predict for each grid point\n",
        "Z = svm_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot decision boundary\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Background decision regions\n",
        "plt.contourf(xx, yy, Z, alpha=0.3, cmap=ListedColormap(['red', 'blue']))\n",
        "\n",
        "# Plot Potable = 1 points (blue x)\n",
        "plt.scatter(df_drinking[df_drinking['Potability'] == 1]['Potassium'],\n",
        "            df_drinking[df_drinking['Potability'] == 1]['Sodium'],\n",
        "            color='blue', label=\"Potable (1)\", marker='x', s=80)\n",
        "\n",
        "# Plot Not Potable = 0 points (red o)\n",
        "plt.scatter(df_drinking[df_drinking['Potability'] == 0]['Potassium'],\n",
        "            df_drinking[df_drinking['Potability'] == 0]['Sodium'],\n",
        "            color='red', label=\"Not Potable (0)\", edgecolor='k', marker='o')\n",
        "\n",
        "#log scale\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Potassium\")\n",
        "plt.ylabel(\"Sodium\")\n",
        "plt.title(\"SVM Decision Boundary - Potassium vs Sodium\")\n",
        "\n",
        "# Legend\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n",
        "\n",
        "#Code from Chat GPT"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "19380aec28e99156",
      "metadata": {
        "id": "19380aec28e99156"
      },
      "source": [
        "It is impossible to have a perfect boundary between the potable and not potable data. There is some overlap, but the majority of the points are classified correctly. To have more detailed partitioning of the data, one needs more complex methods. Addtional clases at CMU teach these methods"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2b8c17d2b37e1f",
      "metadata": {
        "id": "f2b8c17d2b37e1f"
      },
      "source": [
        "KNN and can SVM look similar. It is out of the scope of this course to explain the pros and cons of each method. Know there are differences for when to use and benefits and challenges of each method."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53aeb5b49c9cee20",
      "metadata": {
        "id": "53aeb5b49c9cee20"
      },
      "source": [
        "# Part 4: Compare models\n",
        "12707: 20 points, 12607: 18 points\n",
        "\n",
        "12607: Skip 15\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646767ff3d027220",
      "metadata": {
        "id": "646767ff3d027220"
      },
      "source": [
        "The real power is when you can compare models. Fill out the list of what you have learned. Hint, you will use all of these methods later."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1bbc0e26a48bf83",
      "metadata": {
        "id": "b1bbc0e26a48bf83"
      },
      "source": [
        "1. Regression models\n",
        "2. ? (singular version)  ###\n",
        "3. ? (take a bunch of #3 and then average them) ###\n",
        "4. KNN\n",
        "5. SVM\n",
        "\n",
        "### 12) Fill out 2 and 3\n",
        "\n",
        "'###'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ea36fb05ae01bef",
      "metadata": {
        "id": "6ea36fb05ae01bef"
      },
      "source": [
        "### Here is a list of of the packages that are used to run all of the models together"
      ]
    },
    {
      "cell_type": "code",
      "id": "4e001303c4bf2d2c",
      "metadata": {
        "id": "4e001303c4bf2d2c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "## Importing the ML package to split the data into a\n",
        "# testing and training subsets to train and run the ML model\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "## Importing ML packages to be able to set data\n",
        "# with words to be values, if needed\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "## Importing ML package for simple vector machines\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "## Importing ML package for k nearest neighbor\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "## Importing the ML package to be able to run a\n",
        "# decision tree regression model\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "## Importing ML package to run RandomForest\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "## Importing the ML package to be able to run linear regression\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "## Importing error metrics for MSE and R2 value\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "9c0f19d56147659b",
      "metadata": {
        "id": "9c0f19d56147659b"
      },
      "source": [
        "### Here we import another similar dataset. This will show us how ML models act differently based on each dataset."
      ]
    },
    {
      "cell_type": "code",
      "id": "58d0898187482305",
      "metadata": {
        "id": "58d0898187482305"
      },
      "source": [
        "df_irrigation = pd.read_csv('IrrigationWater_Final_Dataset.csv')\n",
        "df_irrigation.head()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "4957b020da5a53fd",
      "metadata": {
        "id": "4957b020da5a53fd"
      },
      "source": [
        "#Re-importing data to look at all of the columns\n",
        "df_drinking = pd.read_csv('DrinkingWater_Final_Dataset.csv')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "4269cd9f72697e04",
      "metadata": {
        "id": "4269cd9f72697e04"
      },
      "source": [
        "### Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "id": "c6f90ed1ce4de453",
      "metadata": {
        "id": "c6f90ed1ce4de453"
      },
      "source": [
        "def preprocess_data(df):\n",
        "    df = df.dropna()  # Drop missing values\n",
        "    X = df.iloc[:, :-1]  # Features (all columns except last)\n",
        "    y = df.iloc[:, -1]   # Target (last column)\n",
        "\n",
        "    # Encode categorical variables if any\n",
        "    for col in X.select_dtypes(include=['object']).columns:\n",
        "        X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return X_scaled, y\n",
        "\n",
        "# Prepare data\n",
        "X_irrigation, y_irrigation = preprocess_data(df_irrigation)\n",
        "X_drinking, y_drinking = preprocess_data(df_drinking)\n",
        "\n",
        "#Code from Chat GPT"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "dc154364854cdbfc",
      "metadata": {
        "id": "dc154364854cdbfc"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e52a40fb0fbebcb3",
      "metadata": {
        "id": "e52a40fb0fbebcb3"
      },
      "source": [
        "### 13) Set your test and train dataset size and your random state. If you have a logical test size, full credit will be awarded.\n",
        "'###'"
      ]
    },
    {
      "cell_type": "code",
      "id": "54c85377d8631571",
      "metadata": {
        "id": "54c85377d8631571"
      },
      "source": [
        "# Split datasets\n",
        "(X_train_irrigation, X_test_irrigation, y_train_irrigation,\n",
        " y_test_irrigation) = train_test_split(X_irrigation,\n",
        "                                       y_irrigation, test_size=###, random_state=###)\n",
        "(X_train_drinking, X_test_drinking, y_train_drinking,\n",
        " y_test_drinking) = train_test_split(X_drinking,\n",
        "                                     y_drinking, test_size=###, random_state=###)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "7942caeb5e578bc9",
      "metadata": {
        "id": "7942caeb5e578bc9"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "96efabb870e44f63",
      "metadata": {
        "id": "96efabb870e44f63"
      },
      "source": [
        "### Run the models"
      ]
    },
    {
      "cell_type": "code",
      "id": "8ffc54fd3673ca32",
      "metadata": {
        "id": "8ffc54fd3673ca32"
      },
      "source": [
        "# Define models\n",
        "models = {\n",
        "    \"SVM\": SVR(),\n",
        "    \"KNN\": KNeighborsRegressor(),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(),\n",
        "    \"Random Forest\": RandomForestRegressor(),\n",
        "    \"Linear Regression\": LinearRegression()\n",
        "}\n",
        "\n",
        "# Function to train and evaluate models\n",
        "def evaluate_models(models, X_train, X_test, y_train, y_test):\n",
        "    results = []\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        results.append([name, mse, rmse, r2])\n",
        "    return pd.DataFrame(results, columns=[\"Model\", \"MSE\", \"RMSE\", \"R²\"])\n",
        "\n",
        "# Evaluate models on both datasets\n",
        "results_irrigation = evaluate_models(models,\n",
        "                                     X_train_irrigation, X_test_irrigation, y_train_irrigation, y_test_irrigation)\n",
        "results_drinking = evaluate_models(models,\n",
        "                                   X_train_drinking, X_test_drinking,\n",
        "                                   y_train_drinking, y_test_drinking)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "12f07e78a2f4904c",
      "metadata": {
        "id": "12f07e78a2f4904c"
      },
      "source": [
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "dc24d1b2bfe062da",
      "metadata": {
        "id": "dc24d1b2bfe062da"
      },
      "source": [
        "Compare the models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe351ece1c294489",
      "metadata": {
        "id": "fe351ece1c294489"
      },
      "source": [
        "### 14) What were the best 2 models for the drinking water data. Why do you say this?\n",
        "'###'"
      ]
    },
    {
      "metadata": {
        "id": "d04a5ec4b82c272a"
      },
      "cell_type": "markdown",
      "source": [
        "*answer here*"
      ],
      "id": "d04a5ec4b82c272a"
    },
    {
      "cell_type": "code",
      "id": "1ec2f85888e19425",
      "metadata": {
        "id": "1ec2f85888e19425"
      },
      "source": [
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "d9c2b70121da14e2",
      "metadata": {
        "id": "d9c2b70121da14e2"
      },
      "source": [
        "### 15) What were the 2 worst models for the irrigation data. Why do you say this?\n",
        "#### 12607: Skip\n",
        "'###'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a0af6227f63213",
      "metadata": {
        "id": "b9a0af6227f63213"
      },
      "source": [
        "# Part 5: Feature Importance\n",
        "12707: 26 points, 12607: 34.5 points\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c509cefa10605805",
      "metadata": {
        "id": "c509cefa10605805"
      },
      "source": [
        "In machine learning, feature importance refers to a technique used to determine how much each feature (or input variable) contributes to the predictive power of a model.\n",
        "\n",
        "Understanding Feature Importance in Machine Learning. (n.d.). Built In. Retrieved March 8, 2025, from https://builtin.com/data-science/feature-importance\n",
        "\n",
        "\n",
        "We are going to provide you code for feature importance for our models and ask you to explain how this information helps your understanding of the data and the ability to predict if the water is potable or not\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40fa387542cbae95",
      "metadata": {
        "id": "40fa387542cbae95"
      },
      "source": [
        "SVM feature importance"
      ]
    },
    {
      "cell_type": "code",
      "id": "cd841ee4e08e0847",
      "metadata": {
        "id": "cd841ee4e08e0847"
      },
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "# Train separate SVM models for each dataset before computing feature importance\n",
        "svm_model_irrigation = SVR()\n",
        "svm_model_irrigation.fit(X_train_irrigation, y_train_irrigation)\n",
        "\n",
        "svm_model_drinking = SVR()\n",
        "svm_model_drinking.fit(X_train_drinking, y_train_drinking)\n",
        "\n",
        "\n",
        "# Compute feature importance for SVM on Drinking Water dataset\n",
        "svm_importance_drinking = permutation_importance(svm_model_drinking,\n",
        "                                                 X_test_drinking, y_test_drinking,\n",
        "                                                 scoring=\"r2\", n_repeats=10,\n",
        "                                                 random_state=42)\n",
        "feature_importance_drinking = pd.DataFrame({\n",
        "    \"Feature\": df_drinking.columns[:-1],\n",
        "    \"Importance\": svm_importance_drinking.importances_mean\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "\n",
        "# Plot feature importance for Drinking Water dataset\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(feature_importance_drinking[\"Feature\"],\n",
        "         feature_importance_drinking[\"Importance\"], color=\"green\")\n",
        "plt.xlabel(\"Feature Importance Score\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.title(\"Feature Importance for SVM (Drinking Water)\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "svm_importance_irrigation = (permutation_importance\n",
        "                             (svm_model_irrigation, X_test_irrigation,\n",
        "                              y_test_irrigation, scoring=\"r2\", n_repeats=10,\n",
        "                              random_state=42))\n",
        "feature_importance_irrigation = pd.DataFrame({\n",
        "    \"Feature\": df_irrigation.columns[:-1],\n",
        "    \"Importance\": svm_importance_irrigation.importances_mean\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "# Plot feature importance for Drinking Water dataset\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(feature_importance_irrigation[\"Feature\"],\n",
        "         feature_importance_irrigation[\"Importance\"], color=\"blue\")\n",
        "plt.xlabel(\"Feature Importance Score\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.title(\"Feature Importance for SVM (Irrigation Water)\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "f6b4b2ad15266f8f",
      "metadata": {
        "id": "f6b4b2ad15266f8f"
      },
      "source": [
        "### 16) Using the results from the SVM model provided above, write a policy brief to the Chicago Water Authority using the 3-section sentence classification method.\n",
        "##### Focus Topic: Drinking Water Quality\n",
        "##### Assumption: The dataset reflects measurements from the City of Chicago’s drinking water system.\n",
        "##### Your goal is to develop a data-driven recommendation to improve or monitor water quality.\n",
        "###### Format:\n",
        "* Summary: 2 sentences\n",
        "* Background: 2–3 sentences\n",
        "* Recommendations: 2–3 bullet points\n",
        "\n",
        "\n",
        "\n",
        "--------------------\n",
        "Basic and informal example:\n",
        "Hello Chicago Water Authority,\n",
        "\n",
        "Recent testing and modeling show that certain elements significantly affect water quality. These elements help determine whether the water is safe to drink.\n",
        "I conducted an analysis using a Support Vector Machine (SVM) model, which revealed that sulfate has the strongest influence on whether the water is potable. Sulfate is a compound that dissolves easily in water and may come from natural or industrial sources.\n",
        "To address sulfate levels in drinking water, I recommend the following:\n",
        "1. Conduct regular odor tests; sulfate may give off a rotten egg smell.\n",
        "2. Use annual visual tests such as placing white paper under tap water to detect discoloration from sulfur.\n",
        "\n",
        "\n",
        "'###'"
      ]
    },
    {
      "metadata": {
        "id": "af31cc7ddc4ff8e0"
      },
      "cell_type": "markdown",
      "source": [
        "*answer here*"
      ],
      "id": "af31cc7ddc4ff8e0"
    },
    {
      "metadata": {
        "id": "f225fdbcb237794b"
      },
      "cell_type": "markdown",
      "source": [
        " ### 17) Add an addendum to your memo that addresses the validity and limitations of your SVM analysis.\n",
        " ####  This section should serve as a disclaimer or caution for policymakers reading your recommendation. Your goal is to acknowledge any uncertainties, model accuracy concerns, or data limitations that could impact how your results are interpreted or implemented.\n",
        "\n",
        "###### Format:\n",
        "Title the section: “Model Limitations & Considerations”\n",
        "* Include 2–3 sentences describing:\n",
        "    * Potential issues with accuracy or generalizability of the model\n",
        "    * Any assumptions or data limitations that should be considered\n",
        "    * Suggestions for future analysis or improvements\n",
        "\n",
        "This addendum should be written in a way that could realistically appear at the end of a professional policy memo.\n",
        "\n",
        "'###'"
      ],
      "id": "f225fdbcb237794b"
    },
    {
      "cell_type": "markdown",
      "id": "33c4457ced170278",
      "metadata": {
        "id": "33c4457ced170278"
      },
      "source": [
        "*answer here*"
      ]
    },
    {
      "metadata": {
        "id": "a474ef8df1fc94c1"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "NOTE: some of you may have issues with exporting the code to a pdf, if you have this issue remove the images for KNN and SVM."
      ],
      "id": "a474ef8df1fc94c1"
    },
    {
      "metadata": {
        "id": "3fca9a08376419ad"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [],
      "id": "3fca9a08376419ad"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}